{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\laksh\\anaconda3\\envs\\cvenv\\lib\\site-packages (3.10.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\laksh\\anaconda3\\envs\\cvenv\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\laksh\\anaconda3\\envs\\cvenv\\lib\\site-packages (from SpeechRecognition) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\laksh\\anaconda3\\envs\\cvenv\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\laksh\\anaconda3\\envs\\cvenv\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\laksh\\anaconda3\\envs\\cvenv\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laksh\\anaconda3\\envs\\cvenv\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\laksh\\anaconda3\\envs\\cvenv\\lib\\site-packages (0.2.14)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer=sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.energy_threshold=300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Speech Recognition Functions**\n",
    "For recognizing speech from audio data using different APIs there is a recognizer class that does all the work.\n",
    "\n",
    "recognize_houndify(): Houndify by SoundHound\n",
    "recognize_ibm(): IBM Speech to Text\n",
    "recognize_sphinx(): CMU Sphinx – requires installing PocketSphinx\n",
    "recognize_google(): Google Web Speech API\n",
    "recognize_google_cloud(): Google Cloud Speech – requires installation of the google-cloud-speech package\n",
    "The recognize_sphinx() has benefits as it can work offline with the CMU Sphinx engine. The other requires a stable internet connection.\n",
    "\n",
    "Google offers it is own API recognize_google() which is free and it also does not require any API key for use. Well, there is one drawback about google speech recognition that is limiting you went you try to process the audio data which have a longer time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Audio Preprocessing**\n",
    "\n",
    "While passing the audio data if you get an error it is due to the wrong data type format for the audio file. To avoid this kind of situation preprocessing of audio data is a must there is a class especially for preprocessing the audio file which is called AudioFile.\n",
    "\n",
    "For this example, you can download any audio file. But if you want to use your own voice for the audio files you just need to run the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something!\n",
      "Audio saved as microphone-results.wav\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# obtain audio from the microphone\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Say something!\")\n",
    "    audio = recognizer.listen(source)\n",
    "\n",
    "    #write audio to a wav file\n",
    "with open(\"microphone-results.wav\", \"wb\") as f:\n",
    "    f.write(audio.get_wav_data())\n",
    "    print(\"Audio saved as microphone-results.wav\")   \n",
    "\n",
    "\n",
    "#*******\n",
    "\n",
    "#     # recognize speech using Google Speech Recognition\n",
    "#     text = r.recognize_google(audio)\n",
    "#     print(\"Google Speech Recognition thinks you said:\", text)\n",
    "\n",
    "# except sr.UnknownValueError:\n",
    "#     print(\"Google Speech Recognition could not understand audio\")\n",
    "# except sr.RequestError as e:\n",
    "#     print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n",
    "# except Exception as e:\n",
    "#      print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Audio processing code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioFile"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "recognizer=sr.Recognizer()\n",
    "\n",
    "audio_file=sr.AudioFile(\"microphone-results.wav\")\n",
    "type(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Record**\n",
    "So, let’s convert it into **audio to audio data** with the help of a record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.audio.AudioData"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file = sr.AudioFile(\"microphone-results.wav\")\n",
    "\n",
    "with audio_file as source:\n",
    "  audio_file = recognizer.record(source)\n",
    "  recognizer.recognize_google(audio_data=audio_file)\n",
    "\n",
    "type(audio_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Duration:**\n",
    "Duration is used when you want specific audio from the audio data to let’s say you want only the first 5 seconds of the entire audio data, so now we have to set the duration parameter to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good morning are you everyone'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file = sr.AudioFile(\"microphone-results.wav\")\n",
    "with audio_file as source:\n",
    "  audio_file = recognizer.record(source, duration = 5.0)\n",
    "  result = recognizer.recognize_google(audio_data=audio_file)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Offset:** \n",
    "Offset is mainly used when we need to cut off some seconds at the starting of the audio data. Let’s see if you don’t want to listen or need the first 5 seconds of the audio then you have to set the offset parameter to 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good morning are you everyone'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# audio_file = sr.AudioFile(\"microphone-results.wav\")\n",
    "# with audio_file as source:\n",
    "#   audio_file = recognizer.record(source, offset = 1.0)\n",
    "#   result = recognizer.recognize_google(audio_data=audio_file)\n",
    "audio_file = sr.AudioFile(\"microphone-results.wav\")\n",
    "\n",
    "with audio_file as source:\n",
    "  audio_file = recognizer.record(source, offset = 0.01)\n",
    "  result = recognizer.recognize_google(audio_data=audio_file)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The Effect of Noise on Speech Recognition**\n",
    "We won’t get noise-free data every time. All audio files have some degree of noise in them from the start and this un-handled noise will affect the accuracy of the Speech Recognition system.\n",
    "\n",
    "Let’s see an example where we will see how a noise audio file affects the accuracy of the Speech Recognition system. You can download the audio file “jackhammer.wav” file here. Don’t forget to download the audio file into your current working directory.\n",
    "\n",
    "First, let’s run the code and see what output is seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good morning are you everyone'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizer = sr.Recognizer()\n",
    "jackhammer = sr.AudioFile('microphone-results.wav')\n",
    "with jackhammer as source:\n",
    "    audio = recognizer.record(source)\n",
    "    \n",
    "recognizer.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohh hell no this won’t work but we have the solution we can use the adjust_for_ambient_noise method of the Recognizer class. Let’s re-run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = sr.AudioFile(\"microphone-results.wav\")\n",
    "with jackhammer as source:\n",
    "    recognizer.adjust_for_ambient_noise(source, duration=0.5)\n",
    "    audio = recognizer.record(source)\n",
    "\n",
    "recognizer.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **adjust_for_ambient_noise methods** \n",
    "work for this audio and we got a closer output but it is not correct for cases like this we need to pre-process the audio file which can be done with audio editing software or a Python package (such as SciPy).\n",
    "If you don’t want to use the audio file you can also use your voice and the speech_recognition will write down what you speak.\n",
    "The code for the voice coming through the microphone for that we will use pyaudio library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Talking\n",
      "Time over, thank you\n",
      "Text: hey good morning 12345\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "# Initialize recognizer class (for recognizing the speech)\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Reading Microphone as source\n",
    "# listening the speech and store in audio_text variable\n",
    "with sr.Microphone() as source:\n",
    "    print(\"Start Talking\")\n",
    "    audio_text = recognizer.listen(source)\n",
    "    print(\"Time over, thank you\")\n",
    "    \n",
    "    try:\n",
    "        # using google speech recognition\n",
    "        print(\"Text: \"+recognizer.recognize_google(audio_text))\n",
    "    except:\n",
    "         print(\"Sorry, I did not get that\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
